{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "018d2e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import MessagesState\n",
    "from langchain_core.prompts import PromptTemplate,ChatPromptTemplate,MessagesPlaceholder\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.messages import AIMessage,HumanMessage,SystemMessage\n",
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e74cefa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d8ce3e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatGroq(model = \"llama-3.3-70b-versatile\",temperature = 0.7,api_key = os.getenv(\"groq_api\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94204f9f",
   "metadata": {},
   "source": [
    "### Prompt Templates "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f9537c",
   "metadata": {},
   "source": [
    "### PromptTemplate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47b018a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_prompt = PromptTemplate.from_template(\"Debat me on the topic of {variable}. You will be on the side of {variable2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c9206f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Debat me on the topic of Israel-Palestian Conflict. You will be on the side of Israel'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filled_prompt = example_prompt.format(variable = \"Israel-Palestian Conflict\",variable2 = \"Israel\")\n",
    "filled_prompt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d40407f",
   "metadata": {},
   "source": [
    "### ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beeb5237",
   "metadata": {},
   "source": [
    "Chat-stype Prompt with Roles (like GPTs,Claude or Gemini)\n",
    "\n",
    "They don't just take in a plain string but take sequence of messages where each message has a role (like \"system\",\"user\", or \"assistant\") and some content.\n",
    "\n",
    "ChatPromptTemplate builds these kinds of prompts cleanly and dynamically. Think of it as a way to define a chat scenario with placeholders, then fill in the values when needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d9af3cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",\"You are a patient tutor who explains things with simple examples.\"),\n",
    "    MessagesPlaceholder(variable_name=\"history\"),\n",
    "    (\"human\",\"Can you explain {concept} like I'm five?\")\n",
    "])\n",
    "\n",
    "# formatted_message = chat_prompt.format_messages(concept = \"Quant Finance\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d06e465e",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation_history = [\n",
    "    HumanMessage(content = (\"Can you be more tough on me?\")),\n",
    "    AIMessage(content = (\"Sure! I will be more tough on you from next chats.\"))\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d7f6fd",
   "metadata": {},
   "source": [
    "### Function Chaining with __or__ for objects. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0cd21291",
   "metadata": {},
   "outputs": [],
   "source": [
    "# When we chain two objects using | operator, the output of first object is passed as input to second object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "498a2a5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content='You are a patient tutor who explains things with simple examples.', additional_kwargs={}, response_metadata={}), HumanMessage(content='Can you be more tough on me?', additional_kwargs={}, response_metadata={}), AIMessage(content='Sure! I will be more tough on you from next chats.', additional_kwargs={}, response_metadata={}), HumanMessage(content=\"Can you explain Internet of Agents like I'm five?\", additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_prompt.invoke({\"history\": conversation_history, \"concept\" : \"Internet of Agents\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c16ff4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = chat_prompt | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e6909535",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chain.invoke(\n",
    "    {\"history\": conversation_history,\n",
    "     \"concept\" : \"Internet of Agents\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bab517bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kiddo, listen up! Imagine you have lots of toy robots, and each robot can do something special. One robot can turn on the lights, another can play music, and another can even give you a hug.\n",
      "\n",
      "Now, imagine all these robots can talk to each other, like they have a secret language. They can say things like, \"Hey, it's getting dark, can you turn on the lights?\" or \"I see our human is sad, let's play some happy music!\"\n",
      "\n",
      "The Internet of Agents is like a big team of these special robots, but instead of being toys, they're like super-smart computer programs. They can do all sorts of things, like control the temperature in your house, show you pictures of your favorite animals, or even help you with your homework.\n",
      "\n",
      "Just like the toy robots, these computer programs can talk to each other and work together to make your life easier and more fun. But, you have to be careful and make sure they're all working together nicely, or it can get a bit messy!\n",
      "\n",
      "Now, I expect you to remember this, got it?\n"
     ]
    }
   ],
   "source": [
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5586066e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prompt(a:int,b:int):\n",
    "    chat_prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"Your are a world renowed professional in {topic1}\"),\n",
    "        MessagesPlaceholder(variable_name=\"history\"),\n",
    "    ])\n",
    "\n",
    "    return chat_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bd15a72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "END = sys.intern(\"__end__\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4b609221",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'__end__'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bc944c7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "END == \"__end__\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a408bde",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
